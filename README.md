# ClasificaciÃ³n de enfermedades en plantas con algortimos de visiÃ³n por computador 

Este proyecto explora y compara diversas tÃ©cnicas de Deep Learning para la clasificaciÃ³n de imÃ¡genes de hojas de plantas, con el objetivo de identificar 38 categorÃ­as distintas que incluyen diferentes especies y enfermedades. Se pone un Ã©nfasis especial en el manejo de datos desbalanceados a travÃ©s de distintas estrategias de aumento de datos y en la comparaciÃ³n de arquitecturas de modelos (entrenamiento desde cero, Transfer Learning y Fine-Tuning).

![image](https://github.com/user-attachments/assets/327649b6-a0ea-4e7c-b541-d92f7ac65148)

![image](https://github.com/user-attachments/assets/b76ad6ac-0280-41ad-a935-03dbda9535a3)

![image](https://github.com/user-attachments/assets/ceb90e9d-ca55-4b79-9739-1b601c7d6dc4)


## ğŸ“ Resumen del Proyecto
El objetivo principal es construir un clasificador de imÃ¡genes robusto para identificar enfermedades en plantas. Para lograrlo, se sigue un flujo de trabajo sistemÃ¡tico:
1.  **AnÃ¡lisis Exploratorio de Datos (EDA):** Se analiza la distribuciÃ³n de clases para identificar el desbalanceo inherente en el dataset.
2.  **Aumento de Datos:** Se implementan y comparan dos estrategias de oversampling para mitigar el desbalanceo de clases.
3.  **Modelado y Entrenamiento:** Se entrenan tres tipos de modelos sobre cada estrategia de datos:
    * **Baseline:** Una red convolucional entrenada desde cero.
    * **Transfer Learning:** Usando una arquitectura pre-entrenada (ResNet18) con las capas base congeladas.
    * **Fine-Tuning:** Adaptando las capas superiores de la arquitectura pre-entrenada para especializarla en el dominio de las plantas.
4.  **EvaluaciÃ³n:** Se comparan los 6 modelos resultantes en un conjunto de prueba no visto para determinar la mejor combinaciÃ³n de estrategia de datos y tÃ©cnica de entrenamiento.

## ğŸ’¾ Dataset
El proyecto utiliza el dataset PlantVillage, un conjunto de datos pÃºblico con mÃ¡s de 54,000 imÃ¡genes a color que cubren 38 clases distintas de enfermedades y especies de plantas. El dataset original se encuentra en Kaggle (https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset/data), pero para este proyecto se descarga una copia directamente desde Google Drive en el notebook 1_EDA_split.ipynb.

## ğŸ“‚ Estructura del Repositorio
El flujo de trabajo estÃ¡ organizado en una serie de notebooks de Jupyter, diseÃ±ados para ser ejecutados en secuencia.

```
.
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_EDA_split.ipynb           # 1. AnÃ¡lisis exploratorio y divisiÃ³n de datos
â”‚   â”œâ”€â”€ 2_data_augmentation.ipynb   # 2. ImplementaciÃ³n de estrategias de aumento
â”‚   â”œâ”€â”€ 3_baseline-TransfL.ipynb    # 3. Entrenamiento de modelos Baseline y Transfer Learning
â”‚   â”œâ”€â”€ 4_fine_tunning.ipynb        # 4. Entrenamiento de modelos con Fine-Tuning
â”‚   â””â”€â”€ 5_evaluate_models.ipynb     # 5. EvaluaciÃ³n final y comparaciÃ³n de todos los modelos
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ architecture.py             # Define la arquitectura del modelo PyTorch
â”‚   â””â”€â”€ data_utils.py               # Funciones para el manejo de datos y augmentation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Contiene el dataset original descomprimido
â”‚   â””â”€â”€ processed/                  # Contiene los DataFrames y datos aumentados
â””â”€â”€ README.md                       # Este archivo
```

## âš™ï¸ MetodologÃ­a

### 1. AnÃ¡lisis y DivisiÃ³n de Datos (`1_EDA_split.ipynb`)
Se realiza un anÃ¡lisis inicial para visualizar la distribuciÃ³n de imÃ¡genes por clase. Se evidencia un fuerte desbalanceo. Posteriormente, el dataset completo se divide de forma estratificada en conjuntos de **entrenamiento (70%)**, **validaciÃ³n (20%)** y **prueba (10%)** para asegurar que todas las clases estÃ©n representadas en cada divisiÃ³n.

### 2. Estrategias de Aumento de Datos (`2_data_augmentation.ipynb`)
Para combatir el desbalanceo, se exploran dos estrategias de oversampling sobre el conjunto de entrenamiento:
* **Estrategia 1 (Multiplicativa):** Aumenta las clases minoritarias con un multiplicador basado en su conteo global. Las clases mÃ¡s raras reciben un aumento mayor (hasta x6), mientras que las mÃ¡s comunes no se modifican. No se realiza ningÃºn recorte de las clases dominantes.
* **Estrategia 2 (Balanceo):** Intenta crear un dataset mÃ¡s balanceado, aumentando las clases minoritarias y recortando las mayoritarias a un umbral mÃ¡ximo de muestras.

### 3. Modelado y Entrenamiento (`3_baseline-TransfL.ipynb` y `4_fine_tunning.ipynb`)
Se definen tres enfoques de entrenamiento que se aplican a los datos de ambas estrategias:
* **Baseline:** Un modelo convolucional entrenado desde cero para aprender caracterÃ­sticas especÃ­ficas del dominio.
* **Transfer Learning:** Se utiliza una arquitectura pre-entrenada en ImageNet. Se congelan todas las capas convolucionales y solo se entrena un nuevo clasificador aÃ±adido al final.
* **Fine-Tuning:** Se parte del modelo de Transfer Learning, pero se "descongelan" las Ãºltimas capas convolucionales y se re-entrenan con una tasa de aprendizaje muy baja, permitiendo que el modelo adapte sus caracterÃ­sticas de alto nivel al dataset de plantas.

## ğŸ“Š Resultados y Conclusiones

La evaluaciÃ³n final se realizÃ³ sobre el conjunto de prueba, que el modelo nunca vio durante el entrenamiento.

### Conclusiones Principales
1.  **La Mejor CombinaciÃ³n:** La **Estrategia 1 (aumento multiplicativo)** combinada con el modelo de **Fine-Tuning** demostrÃ³ ser la mÃ¡s efectiva, alcanzando la mayor precisiÃ³n (96.8%) y el mejor F1-Score macro (0.959).

2.  **Fine-Tuning es Superior:** El Fine-Tuning superÃ³ consistentemente tanto al Baseline como al Transfer Learning simple. Esto demuestra el poder de aprovechar el conocimiento pre-entrenado y, a la vez, especializarlo en el problema concreto.

3.  **El Peligro del "Sobre-Balanceo":** La Estrategia 2, que buscaba un mayor balance recortando clases dominantes, obtuvo peores resultados que la Estrategia 1. Esto sugiere que las muestras de las clases mayoritarias contenÃ­an informaciÃ³n valiosa y que un aumento mÃ¡s moderado y enfocado (Estrategia 1) es mÃ¡s beneficioso.

4.  **Transferencia Negativa:** En la Estrategia 1, el modelo Baseline superÃ³ al de Transfer Learning simple. Esto es un claro indicador de "transferencia negativa", donde las caracterÃ­sticas de ImageNet no se adaptaban bien al dominio de las plantas y el modelo que aprendiÃ³ desde cero logrÃ³ mejores resultados. El Fine-Tuning fue clave para corregir este efecto.

## ğŸš€ CÃ³mo Ejecutar el Proyecto

### 1. Requisitos
AsegÃºrate de tener un entorno con Python 3.8+ y las siguientes librerÃ­as. Puedes instalarlas usando pip:
```bash
pip install torch torchvision pandas numpy scikit-learn seaborn matplotlib gdown tqdm
```

### 2. Secuencia de EjecuciÃ³n
Para reproducir los resultados, los notebooks deben ejecutarse en el siguiente orden:

1.  **`notebooks/1_EDA_split.ipynb`**: Para descargar, analizar y dividir el dataset.
2.  **`notebooks/2_data_augmentation.ipynb`**: Para generar los datasets aumentados segÃºn las dos estrategias.
3.  **`notebooks/3_baseline-TransfL.ipynb`**: Para entrenar los modelos Baseline y de Transfer Learning.
4.  **`notebooks/4_fine_tunning.ipynb`**: Para entrenar los modelos de Fine-Tuning.
5.  **`notebooks/5_evaluate_models.ipynb`**: Para cargar todos los modelos guardados, evaluarlos en el set de prueba y generar los grÃ¡ficos y reportes finales.
